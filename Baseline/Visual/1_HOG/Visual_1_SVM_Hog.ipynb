{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from time import time\n",
    "import datetime\n",
    "import pandas as pd\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.metrics import roc_auc_score, recall_score, accuracy_score, f1_score\n",
    "from sklearn.multiclass import OneVsRestClassifier, OneVsOneClassifier\n",
    "from sklearn.preprocessing import label_binarize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (1) load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>970</th>\n",
       "      <th>971</th>\n",
       "      <th>972</th>\n",
       "      <th>973</th>\n",
       "      <th>974</th>\n",
       "      <th>975</th>\n",
       "      <th>976</th>\n",
       "      <th>977</th>\n",
       "      <th>978</th>\n",
       "      <th>979</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11460</th>\n",
       "      <td>-3.610809</td>\n",
       "      <td>0.181031</td>\n",
       "      <td>2.727854</td>\n",
       "      <td>-0.941375</td>\n",
       "      <td>0.672853</td>\n",
       "      <td>1.070195</td>\n",
       "      <td>0.235489</td>\n",
       "      <td>-0.543350</td>\n",
       "      <td>-0.829860</td>\n",
       "      <td>-0.318676</td>\n",
       "      <td>...</td>\n",
       "      <td>0.049048</td>\n",
       "      <td>-0.068235</td>\n",
       "      <td>-0.064671</td>\n",
       "      <td>0.067637</td>\n",
       "      <td>-0.012281</td>\n",
       "      <td>-0.067218</td>\n",
       "      <td>0.074663</td>\n",
       "      <td>0.002308</td>\n",
       "      <td>0.072913</td>\n",
       "      <td>-0.013657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9610</th>\n",
       "      <td>-1.162428</td>\n",
       "      <td>-2.319746</td>\n",
       "      <td>2.544356</td>\n",
       "      <td>0.793281</td>\n",
       "      <td>1.347436</td>\n",
       "      <td>-1.824822</td>\n",
       "      <td>0.855603</td>\n",
       "      <td>1.427280</td>\n",
       "      <td>-0.349576</td>\n",
       "      <td>0.365939</td>\n",
       "      <td>...</td>\n",
       "      <td>0.036044</td>\n",
       "      <td>-0.077791</td>\n",
       "      <td>0.026761</td>\n",
       "      <td>0.016202</td>\n",
       "      <td>-0.008609</td>\n",
       "      <td>-0.040978</td>\n",
       "      <td>-0.002687</td>\n",
       "      <td>-0.006296</td>\n",
       "      <td>0.022981</td>\n",
       "      <td>0.018608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2186</th>\n",
       "      <td>2.606377</td>\n",
       "      <td>1.070886</td>\n",
       "      <td>-3.198655</td>\n",
       "      <td>-2.085576</td>\n",
       "      <td>-0.435705</td>\n",
       "      <td>-0.566083</td>\n",
       "      <td>-1.007178</td>\n",
       "      <td>1.235195</td>\n",
       "      <td>-2.404571</td>\n",
       "      <td>1.025328</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.017286</td>\n",
       "      <td>-0.101345</td>\n",
       "      <td>-0.050659</td>\n",
       "      <td>-0.050403</td>\n",
       "      <td>-0.063824</td>\n",
       "      <td>-0.042028</td>\n",
       "      <td>-0.090006</td>\n",
       "      <td>0.035064</td>\n",
       "      <td>0.023151</td>\n",
       "      <td>0.101714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9744</th>\n",
       "      <td>4.561780</td>\n",
       "      <td>-1.153944</td>\n",
       "      <td>0.305514</td>\n",
       "      <td>1.241234</td>\n",
       "      <td>-0.017566</td>\n",
       "      <td>-1.480878</td>\n",
       "      <td>-1.259760</td>\n",
       "      <td>0.253054</td>\n",
       "      <td>-0.589190</td>\n",
       "      <td>0.983693</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.058310</td>\n",
       "      <td>0.027396</td>\n",
       "      <td>-0.040016</td>\n",
       "      <td>-0.052323</td>\n",
       "      <td>-0.004030</td>\n",
       "      <td>-0.040622</td>\n",
       "      <td>-0.013122</td>\n",
       "      <td>-0.021193</td>\n",
       "      <td>0.009634</td>\n",
       "      <td>0.005165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10576</th>\n",
       "      <td>2.124794</td>\n",
       "      <td>0.142205</td>\n",
       "      <td>-0.080546</td>\n",
       "      <td>-2.063062</td>\n",
       "      <td>0.866341</td>\n",
       "      <td>2.338448</td>\n",
       "      <td>-0.582162</td>\n",
       "      <td>1.297541</td>\n",
       "      <td>-2.168625</td>\n",
       "      <td>-0.867786</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.025800</td>\n",
       "      <td>-0.021690</td>\n",
       "      <td>-0.024977</td>\n",
       "      <td>0.106156</td>\n",
       "      <td>0.058931</td>\n",
       "      <td>-0.004661</td>\n",
       "      <td>0.010015</td>\n",
       "      <td>-0.013832</td>\n",
       "      <td>-0.024116</td>\n",
       "      <td>0.068163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6170</th>\n",
       "      <td>-5.219104</td>\n",
       "      <td>5.048948</td>\n",
       "      <td>1.344968</td>\n",
       "      <td>1.433352</td>\n",
       "      <td>0.382586</td>\n",
       "      <td>0.138933</td>\n",
       "      <td>-1.248825</td>\n",
       "      <td>-0.492654</td>\n",
       "      <td>0.576605</td>\n",
       "      <td>0.352858</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.025263</td>\n",
       "      <td>0.035595</td>\n",
       "      <td>0.072347</td>\n",
       "      <td>-0.022745</td>\n",
       "      <td>0.080069</td>\n",
       "      <td>-0.045385</td>\n",
       "      <td>0.056829</td>\n",
       "      <td>0.019796</td>\n",
       "      <td>0.009451</td>\n",
       "      <td>-0.021349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10176</th>\n",
       "      <td>-3.680493</td>\n",
       "      <td>-0.978627</td>\n",
       "      <td>0.705475</td>\n",
       "      <td>2.205018</td>\n",
       "      <td>0.192231</td>\n",
       "      <td>-0.635897</td>\n",
       "      <td>1.776641</td>\n",
       "      <td>-1.439958</td>\n",
       "      <td>-0.275041</td>\n",
       "      <td>1.140577</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000683</td>\n",
       "      <td>0.021049</td>\n",
       "      <td>-0.001623</td>\n",
       "      <td>0.050642</td>\n",
       "      <td>-0.069458</td>\n",
       "      <td>0.064935</td>\n",
       "      <td>0.031490</td>\n",
       "      <td>-0.022713</td>\n",
       "      <td>-0.041155</td>\n",
       "      <td>-0.115849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3482</th>\n",
       "      <td>0.001629</td>\n",
       "      <td>-2.309934</td>\n",
       "      <td>-3.296829</td>\n",
       "      <td>0.544592</td>\n",
       "      <td>-3.328425</td>\n",
       "      <td>-1.253247</td>\n",
       "      <td>-0.654076</td>\n",
       "      <td>1.366200</td>\n",
       "      <td>1.337794</td>\n",
       "      <td>-0.973880</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.022813</td>\n",
       "      <td>-0.007143</td>\n",
       "      <td>-0.042940</td>\n",
       "      <td>-0.014514</td>\n",
       "      <td>0.026099</td>\n",
       "      <td>-0.048444</td>\n",
       "      <td>0.027770</td>\n",
       "      <td>0.078176</td>\n",
       "      <td>-0.032505</td>\n",
       "      <td>0.020063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7451</th>\n",
       "      <td>2.177468</td>\n",
       "      <td>-2.193183</td>\n",
       "      <td>1.687635</td>\n",
       "      <td>1.620445</td>\n",
       "      <td>1.170794</td>\n",
       "      <td>-1.002194</td>\n",
       "      <td>-0.602838</td>\n",
       "      <td>-1.293128</td>\n",
       "      <td>-0.169717</td>\n",
       "      <td>-0.094562</td>\n",
       "      <td>...</td>\n",
       "      <td>0.023281</td>\n",
       "      <td>-0.013745</td>\n",
       "      <td>-0.014041</td>\n",
       "      <td>0.078828</td>\n",
       "      <td>0.015814</td>\n",
       "      <td>0.082901</td>\n",
       "      <td>0.018532</td>\n",
       "      <td>0.001661</td>\n",
       "      <td>0.021490</td>\n",
       "      <td>-0.059198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8248</th>\n",
       "      <td>-2.717009</td>\n",
       "      <td>-1.492730</td>\n",
       "      <td>1.386061</td>\n",
       "      <td>-0.505498</td>\n",
       "      <td>2.272768</td>\n",
       "      <td>-0.542609</td>\n",
       "      <td>1.207733</td>\n",
       "      <td>-0.579735</td>\n",
       "      <td>0.280410</td>\n",
       "      <td>1.607376</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.036958</td>\n",
       "      <td>0.044097</td>\n",
       "      <td>0.007595</td>\n",
       "      <td>0.090048</td>\n",
       "      <td>-0.077743</td>\n",
       "      <td>-0.009369</td>\n",
       "      <td>0.055345</td>\n",
       "      <td>0.037318</td>\n",
       "      <td>-0.008320</td>\n",
       "      <td>0.072395</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8490 rows × 980 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              0         1         2         3         4         5         6  \\\n",
       "11460 -3.610809  0.181031  2.727854 -0.941375  0.672853  1.070195  0.235489   \n",
       "9610  -1.162428 -2.319746  2.544356  0.793281  1.347436 -1.824822  0.855603   \n",
       "2186   2.606377  1.070886 -3.198655 -2.085576 -0.435705 -0.566083 -1.007178   \n",
       "9744   4.561780 -1.153944  0.305514  1.241234 -0.017566 -1.480878 -1.259760   \n",
       "10576  2.124794  0.142205 -0.080546 -2.063062  0.866341  2.338448 -0.582162   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "6170  -5.219104  5.048948  1.344968  1.433352  0.382586  0.138933 -1.248825   \n",
       "10176 -3.680493 -0.978627  0.705475  2.205018  0.192231 -0.635897  1.776641   \n",
       "3482   0.001629 -2.309934 -3.296829  0.544592 -3.328425 -1.253247 -0.654076   \n",
       "7451   2.177468 -2.193183  1.687635  1.620445  1.170794 -1.002194 -0.602838   \n",
       "8248  -2.717009 -1.492730  1.386061 -0.505498  2.272768 -0.542609  1.207733   \n",
       "\n",
       "              7         8         9  ...       970       971       972  \\\n",
       "11460 -0.543350 -0.829860 -0.318676  ...  0.049048 -0.068235 -0.064671   \n",
       "9610   1.427280 -0.349576  0.365939  ...  0.036044 -0.077791  0.026761   \n",
       "2186   1.235195 -2.404571  1.025328  ... -0.017286 -0.101345 -0.050659   \n",
       "9744   0.253054 -0.589190  0.983693  ... -0.058310  0.027396 -0.040016   \n",
       "10576  1.297541 -2.168625 -0.867786  ... -0.025800 -0.021690 -0.024977   \n",
       "...         ...       ...       ...  ...       ...       ...       ...   \n",
       "6170  -0.492654  0.576605  0.352858  ... -0.025263  0.035595  0.072347   \n",
       "10176 -1.439958 -0.275041  1.140577  ... -0.000683  0.021049 -0.001623   \n",
       "3482   1.366200  1.337794 -0.973880  ... -0.022813 -0.007143 -0.042940   \n",
       "7451  -1.293128 -0.169717 -0.094562  ...  0.023281 -0.013745 -0.014041   \n",
       "8248  -0.579735  0.280410  1.607376  ... -0.036958  0.044097  0.007595   \n",
       "\n",
       "            973       974       975       976       977       978       979  \n",
       "11460  0.067637 -0.012281 -0.067218  0.074663  0.002308  0.072913 -0.013657  \n",
       "9610   0.016202 -0.008609 -0.040978 -0.002687 -0.006296  0.022981  0.018608  \n",
       "2186  -0.050403 -0.063824 -0.042028 -0.090006  0.035064  0.023151  0.101714  \n",
       "9744  -0.052323 -0.004030 -0.040622 -0.013122 -0.021193  0.009634  0.005165  \n",
       "10576  0.106156  0.058931 -0.004661  0.010015 -0.013832 -0.024116  0.068163  \n",
       "...         ...       ...       ...       ...       ...       ...       ...  \n",
       "6170  -0.022745  0.080069 -0.045385  0.056829  0.019796  0.009451 -0.021349  \n",
       "10176  0.050642 -0.069458  0.064935  0.031490 -0.022713 -0.041155 -0.115849  \n",
       "3482  -0.014514  0.026099 -0.048444  0.027770  0.078176 -0.032505  0.020063  \n",
       "7451   0.078828  0.015814  0.082901  0.018532  0.001661  0.021490 -0.059198  \n",
       "8248   0.090048 -0.077743 -0.009369  0.055345  0.037318 -0.008320  0.072395  \n",
       "\n",
       "[8490 rows x 980 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filepath ='/home/dell/Xinda/SVM/server/Visual/1_HOG/visual_part2_hog_pca.95_6PNN.csv'\n",
    "data = pd.read_csv(filepath)\n",
    "x = data.iloc[:, :-1]  # 数据特征\n",
    "y = data.iloc[:,-1]  # 标签\n",
    "\n",
    "# 将数据划分为训练集和测试集，test_size=.3表示30%的测试集, 随机数种子, 保证可复现性\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=.3, random_state=423)\n",
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class =  [2 5 0 ... 2 0 0]\n",
      "y_test =     0\n",
      "0  1\n",
      "1  0\n",
      "2  0\n",
      "3  3\n",
      "4  0\n",
      "5  4\n",
      "6  5\n",
      "7  4\n",
      "8  3\n",
      "9  4\n",
      "y.shape= (8490,)\n"
     ]
    }
   ],
   "source": [
    "# 修正测试集和训练集的索引\n",
    "for i in [x_train, x_test, y_train, y_test ]:\n",
    "    i.index  = range(i.shape[0])\n",
    "\n",
    "# Y 将标签编码\n",
    "encoder = LabelEncoder().fit(y_train) # #训练LabelEncoder, 把y_train中的类别编码为0，1，2，3，4，5\n",
    "y = encoder.transform(y_train)\n",
    "print(\"class = \", y)\n",
    "y_train = pd.DataFrame(encoder.transform(y_train)) # 使用训练好的LabelEncoder对源数据进行编码\n",
    "y_test = pd.DataFrame(encoder.transform(y_test))\n",
    "print(\"y_test = \", y_test[0:10])\n",
    "\n",
    "# 标签降维度\n",
    "y_train = y_train.iloc[:,0].ravel()\n",
    "y_test = y_test.iloc[:,0].ravel()\n",
    "print(\"y.shape=\", y_train.shape)\n",
    "\n",
    "# X标准化\n",
    "scaler = StandardScaler()\n",
    "x_train_std = scaler.fit_transform(x_train)  # 标准化\n",
    "x_test_std = scaler.fit_transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy =  0.8147842813959879\n",
      "f1 score =  0.8105617423661162\n",
      "AUC =  0.9647957182128422\n",
      "19:49:739191\n",
      "\n"
     ]
    }
   ],
   "source": [
    "time0 = time()\n",
    "clf = OneVsRestClassifier(\n",
    "        SVC(kernel = 'rbf', \n",
    "        gamma =  0.0009765625,\n",
    "        degree=1, \n",
    "        cache_size=5000,\n",
    "        probability=True,\n",
    "        class_weight='balanced'))\n",
    "clf.fit(x_train_std, y_train)\n",
    "    \n",
    "y_test_prediction = clf.predict(x_test_std)\n",
    "# accuracy\n",
    "accuracy = accuracy_score(y_test,y_test_prediction)\n",
    "print(\"accuracy = \", accuracy)\n",
    "# F1-score\n",
    "f1 = f1_score(y_test,y_test_prediction, average=\"weighted\")\n",
    "print(\"f1 score = \", f1)\n",
    "    \n",
    "# AUC\n",
    "y_test_binary = label_binarize(y_test, classes=list(range(6))) # 转化为one-hot\n",
    "result = clf.decision_function(x_test_std)\n",
    "auc = roc_auc_score(y_test_binary, result, average = 'micro') # 多类分类下，要用概率值（形式二） ，加参数 average='micro'  （不能用ont-hot (形式三) ）\n",
    "print(\"AUC = \", auc)\n",
    "\n",
    "print(datetime.datetime.fromtimestamp(time()-time0).strftime(\"%M:%S:%f\"))\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.13693332, 0.58321393, 0.0215648 , 0.07441558, 0.10204588,\n",
       "        0.0818265 ],\n",
       "       [0.31981876, 0.24446412, 0.02124643, 0.03131904, 0.19812238,\n",
       "        0.18502926],\n",
       "       [0.41383896, 0.00881336, 0.007748  , 0.00866418, 0.09923633,\n",
       "        0.46169917],\n",
       "       ...,\n",
       "       [0.03432759, 0.03021851, 0.01662373, 0.01772152, 0.88344551,\n",
       "        0.01766313],\n",
       "       [0.02009031, 0.19728632, 0.73783727, 0.01192205, 0.03046829,\n",
       "        0.00239576],\n",
       "       [0.04712273, 0.03548223, 0.08156636, 0.78796752, 0.00629756,\n",
       "        0.04156361]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict_proba(x_test_std)  # 输出分类zhidao概率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = clf.predict_proba(x_test_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(result)\n",
    "df.to_csv(\"categorical03_hog_6pnn.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.predict_log_proba(x_test_std)  # 输出分类概率的对数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data={\"hog_prediction_p\": y_test_prediction, \"hog_groundtruth_p\": y_test.tolist()})\n",
    "df.to_csv(\"eval_hog_6pnn.csv\")\n",
    "print(\"save success!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gamma-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gamma_rang: [9.76562500e-04 2.27837703e-03 5.31558594e-03 1.24015707e-02\n",
      " 2.89335848e-02 6.75037337e-02 1.57490131e-01 3.67433623e-01\n",
      " 8.57243983e-01 2.00000000e+00]\n",
      "Start-1, gamma=0.0009765625\n",
      "accuracy =  0.8147842813959879\n",
      "f1 score =  0.8105617423661162\n",
      "AUC =  0.9647957182128422\n",
      "40:40:513247\n",
      "\n",
      "\n",
      "Start-1, gamma=0.0022783770304221013\n",
      "accuracy =  0.8037922506183017\n",
      "f1 score =  0.7944480785258063\n",
      "AUC =  0.9574171929528065\n",
      "01:50:716114\n",
      "\n",
      "\n",
      "Start-1, gamma=0.005315585938181161\n"
     ]
    }
   ],
   "source": [
    "import tqdm\n",
    "times_all = time()\n",
    "# 调试两个参数 gamma & C  ，默认情况下C为1，通常来说这都是一个合理的参数。\n",
    "accuracy_list = []\n",
    "f1_list = []\n",
    "auc_list = []\n",
    "\n",
    "gamma_range = np.logspace(-10, 1, 10, base=2) # 返回13个数字，底是2\n",
    "print(\"gamma_rang:\", gamma_range)\n",
    "\n",
    "for gamma_item in gamma_range:\n",
    "    count=1\n",
    "    time0 = time()\n",
    "    print(\"Start-{0}, gamma={1}\".format(count, gamma_item))\n",
    "    count = count+1\n",
    "    clf = OneVsRestClassifier(\n",
    "        SVC(kernel = 'rbf', \n",
    "        gamma = gamma_item,\n",
    "        degree=1, \n",
    "        cache_size=5000, \n",
    "        class_weight='balanced'))\n",
    "    clf.fit(x_train_std, y_train)\n",
    "    \n",
    "    y_test_prediction = clf.predict(x_test_std)\n",
    "    # accuracy\n",
    "    accuracy = accuracy_score(y_test,y_test_prediction)\n",
    "    accuracy_list.append(accuracy)\n",
    "    print(\"accuracy = \", accuracy)\n",
    "    # F1-score\n",
    "    f1 = f1_score(y_test,y_test_prediction, average=\"weighted\")\n",
    "    print(\"f1 score = \", f1)\n",
    "    f1_list.append(f1)\n",
    "    # AUC\n",
    "    y_test_binary = label_binarize(y_test, classes=list(range(6))) # 转化为one-hot\n",
    "    result = clf.decision_function(x_test_std)\n",
    "    auc = roc_auc_score(y_test_binary, result, average = 'micro') # 多类分类下，要用概率值（形式二） ，加参数 average='micro'  （不能用ont-hot (形式三) ）\n",
    "    print(\"AUC = \", auc)\n",
    "    auc_list.append(auc)\n",
    "    print(datetime.datetime.fromtimestamp(time()-time0).strftime(\"%M:%S:%f\"))\n",
    "    print()\n",
    "    print()\n",
    "\n",
    "print(max(accuracy_list), gamma_range[accuracy_list.index(max(accuracy_list))])\n",
    "print(\"F1-score = \", f1_list[accuracy_list.index(max(accuracy_list))])\n",
    "print(\"AUC-score = \", auc_list[accuracy_list.index(max(accuracy_list))]) \n",
    "print(datetime.datetime.fromtimestamp(time()-times_all).strftime(\"%M:%S:%f\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
