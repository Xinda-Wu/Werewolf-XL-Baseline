{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]\n",
      "CV = 1\n",
      "Test >>> [1, 2, 3, 4, 5, 6, 7, 8, 9] Validation >>> [10, 11, 12, 13, 14, 15]\n",
      "Train >>> [16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]\n",
      "\n",
      "CV = 2\n",
      "Test >>> [10, 11, 12, 13, 14, 15, 16, 17, 18] Validation >>> [19, 20, 21, 22, 23, 24]\n",
      "Train >>> [1, 2, 3, 4, 5, 6, 7, 8, 9, 25, 26, 27, 28, 29, 30]\n",
      "\n",
      "CV = 3\n",
      "Test >>> [19, 20, 21, 22, 23, 24, 25, 26, 27] Validation >>> [28, 29, 30, 1, 2, 3]\n",
      "Train >>> [4, 5, 6, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27]\n",
      "\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "all_session =[i for i in range(1,31)]\n",
    "print(all_session)\n",
    "cv_dataset = {}\n",
    "for i in range(0,3): # CV = 10\n",
    "    if i !=2:\n",
    "        cv_dataset[f\"CV_{i+1}\"] = {\n",
    "            \"Test\":all_session[i*9:9*(i+1)],\n",
    "            \"Validation\":all_session[(i+1)*9:(i+1)*9+6],\n",
    "            \"Train\":list(set(all_session) - set(all_session[i*9:9*(i+1)])- set(all_session[(i+1)*9:(i+1)*9+6]))\n",
    "        }\n",
    "    else:\n",
    "        cv_dataset[f\"CV_{i+1}\"] = {\n",
    "            \"Test\":all_session[i*9:9*(i+1)],\n",
    "            \"Validation\":[28,29,30,1,2,3],\n",
    "            \"Train\":list(set(all_session) - set(all_session[i*3:3*(i+1)])- set([28,29,30,1,2,3]))\n",
    "        }\n",
    "for idx,item in enumerate(cv_dataset):\n",
    "    print(f\"CV = {idx+1}\")\n",
    "    print(f\"Test >>> {cv_dataset[item]['Test']} Validation >>> {cv_dataset[item]['Validation']}\")\n",
    "    print(f\"Train >>> {cv_dataset[item]['Train']}\\n\")\n",
    "print(len(cv_dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add Session Infomation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add Session Information, 先自己加一行 Session列\n",
    "features = pd.read_csv('./1_Features_raw/Regression_Speaker_Visual_hog_final_session.csv')\n",
    "for idx, item in features.iterrows():\n",
    "    session = int(item['VideoName'][:2])\n",
    "    features.iloc[idx, 0] = session\n",
    "features.to_csv('./1_Features_raw/Regression_Speaker_Visual_hog_final_session2.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create CV dataset \n",
    "## (1) For Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# manually delete the first two cols\n",
    "features = pd.read_csv('./1_Features_raw/Classification_Speaker_Visual_Hog_6PNN_session2.csv')\n",
    "participate = pd.read_csv(\"Final_results_0620_1721.csv\")\n",
    "for cv_idx, key in enumerate(cv_dataset):\n",
    "    Test_sessions = cv_dataset[key][\"Test\"]\n",
    "    print(\"Test sessions = \",Test_sessions )\n",
    "    Validation_sessions = cv_dataset[key][\"Validation\"]\n",
    "    Train_sessions = cv_dataset[key][\"Train\"]\n",
    "    \n",
    "    # ---------------------\n",
    "    # load data\n",
    "    # ---------------------\n",
    "    Test_data = features[features['Session'].isin(Test_sessions)]\n",
    "    Test_data.to_csv(f\"./CV_Features_523/ClassificationFeatures/Test_CV_{cv_idx+1}.csv\")\n",
    "    Validation_data = features[features['Session'].isin(Validation_sessions)]\n",
    "    Train_data = features[features['Session'].isin(Train_sessions)]\n",
    "\n",
    "    # ---------------------\n",
    "    # speaker independent\n",
    "    # ---------------------\n",
    "    # (1) delete instance\n",
    "    delete_info = set()\n",
    "    Test_Overlap = participate[participate['Round'].isin(cv_dataset[key][\"Test\"])]\n",
    "    for idx, item in Test_Overlap.iterrows():\n",
    "        values = set(item.values[6:-1])\n",
    "        for temp in values:\n",
    "            if type(temp)!=float:\n",
    "                if int(temp.split('-')[0]) not in Test_sessions:\n",
    "                    if int(temp.split('-')[0])<10:\n",
    "                        temp = '0'+ temp\n",
    "                        delete_info.add(temp.replace(\"-\",\"_\"))\n",
    "                    else:\n",
    "                         delete_info.add(temp.replace(\"-\",\"_\"))\n",
    "    print(delete_info)\n",
    "    \n",
    "    # (2) 整理Validation and Train data\n",
    "    for idx, item in Validation_data.iterrows():\n",
    "        if item['VideoName'][:5] in list(delete_info):\n",
    "            Validation_data.drop(labels = idx,inplace=True)\n",
    "    Validation_data.to_csv(f\"./CV_Features_523/ClassificationFeatures/Validation_CV_{cv_idx+1}.csv\")\n",
    "    \n",
    "    for idx, item in Train_data.iterrows():\n",
    "        if item['VideoName'][:5] in list(delete_info):\n",
    "            Train_data.drop(labels = idx,inplace=True)\n",
    "    Train_data.to_csv(f\"./CV_Features_523/ClassificationFeatures/Train_CV_{cv_idx+1}.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (2) For Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# manually delete the first two cols\n",
    "features = pd.read_csv('./1_Features_raw/Regression_Speaker_Visual_hog_final_session2.csv')\n",
    "participate = pd.read_csv(\"Final_results_0620_1721.csv\")\n",
    "for cv_idx, key in enumerate(cv_dataset):\n",
    "    Test_sessions = cv_dataset[key][\"Test\"]\n",
    "    print(\"Test sessions = \",Test_sessions )\n",
    "    Validation_sessions = cv_dataset[key][\"Validation\"]\n",
    "    Train_sessions = cv_dataset[key][\"Train\"]\n",
    "    \n",
    "    # ---------------------\n",
    "    # load data\n",
    "    # ---------------------\n",
    "    Test_data = features[features['Session'].isin(Test_sessions)]\n",
    "    Test_data.to_csv(f\"./CV_Features/RegressionFeatures/Test_CV_{cv_idx+1}.csv\")\n",
    "    Validation_data = features[features['Session'].isin(Validation_sessions)]\n",
    "    Train_data = features[features['Session'].isin(Train_sessions)]\n",
    "\n",
    "    # ---------------------\n",
    "    # speaker independent\n",
    "    # ---------------------\n",
    "    # (1) delete instance\n",
    "    delete_info = set()\n",
    "    Test_Overlap = participate[participate['Round'].isin(cv_dataset[key][\"Test\"])]\n",
    "    for idx, item in Test_Overlap.iterrows():\n",
    "        values = set(item.values[6:-1])\n",
    "        for temp in values:\n",
    "            if type(temp)!=float:\n",
    "                if int(temp.split('-')[0]) not in Test_sessions:\n",
    "                    if int(temp.split('-')[0])<10:\n",
    "                        temp = '0'+ temp\n",
    "                        delete_info.add(temp.replace(\"-\",\"_\"))\n",
    "                    else:\n",
    "                         delete_info.add(temp.replace(\"-\",\"_\"))\n",
    "    print(delete_info)\n",
    "    \n",
    "    # (2) 整理Validation and Train data\n",
    "    for idx, item in Validation_data.iterrows():\n",
    "        if item['VideoName'][:5] in list(delete_info):\n",
    "            Validation_data.drop(labels = idx,inplace=True)\n",
    "    Validation_data.to_csv(f\"./CV_Features/RegressionFeatures/Validation_CV_{cv_idx+1}.csv\")\n",
    "    \n",
    "    for idx, item in Train_data.iterrows():\n",
    "        if item['VideoName'][:5] in list(delete_info):\n",
    "            Train_data.drop(labels = idx,inplace=True)\n",
    "    Train_data.to_csv(f\"./CV_Features/RegressionFeatures/Train_CV_{cv_idx+1}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.1 64-bit",
   "language": "python",
   "name": "python37164bit395e14d61e31467c92df2f870180e68d"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
