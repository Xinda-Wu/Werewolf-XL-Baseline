{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]\n",
      "{'CV_1': {'Test': [1, 2, 3], 'Validation': [4, 5, 6], 'Train': [7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]}, 'CV_2': {'Test': [4, 5, 6], 'Validation': [7, 8, 9], 'Train': [1, 2, 3, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]}, 'CV_3': {'Test': [7, 8, 9], 'Validation': [10, 11, 12], 'Train': [1, 2, 3, 4, 5, 6, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]}, 'CV_4': {'Test': [10, 11, 12], 'Validation': [13, 14, 15], 'Train': [1, 2, 3, 4, 5, 6, 7, 8, 9, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]}, 'CV_5': {'Test': [13, 14, 15], 'Validation': [16, 17, 18], 'Train': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]}, 'CV_6': {'Test': [16, 17, 18], 'Validation': [19, 20, 21], 'Train': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 22, 23, 24, 25, 26, 27, 28, 29, 30]}, 'CV_7': {'Test': [19, 20, 21], 'Validation': [22, 23, 24], 'Train': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 25, 26, 27, 28, 29, 30]}, 'CV_8': {'Test': [22, 23, 24], 'Validation': [25, 26, 27], 'Train': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 28, 29, 30]}, 'CV_9': {'Test': [25, 26, 27], 'Validation': [28, 29, 30], 'Train': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24]}, 'CV_10': {'Test': [28, 29, 30], 'Validation': [1, 2, 3], 'Train': [4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27]}}\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "all_session =[i for i in range(1,31)]\n",
    "print(all_session)\n",
    "cv_dataset = {}\n",
    "for i in range(0,10): # CV = 10\n",
    "    if i !=9:\n",
    "        cv_dataset[f\"CV_{i+1}\"] = {\n",
    "            \"Test\":all_session[i*3:3*(i+1)],\n",
    "            \"Validation\":all_session[(i+1)*3:3*(i+2)],\n",
    "            \"Train\":list(set(all_session) - set(all_session[i*3:3*(i+1)])- set(all_session[(i+1)*3:3*(i+2)]))\n",
    "        }\n",
    "    else:\n",
    "        cv_dataset[f\"CV_{i+1}\"] = {\n",
    "            \"Test\":all_session[i*3:3*(i+1)],\n",
    "            \"Validation\":[1,2,3],\n",
    "            \"Train\":list(set(all_session) - set(all_session[i*3:3*(i+1)])- set([1,2,3]))\n",
    "        }\n",
    "print(cv_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add Session Infomation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add Session Information, 先自己加一行 Session列\n",
    "features = pd.read_csv('./1_Features_raw/Regression_Speaker_Visual_hog_final_session.csv')\n",
    "for idx, item in features.iterrows():\n",
    "    session = int(item['VideoName'][:2])\n",
    "    features.iloc[idx, 0] = session\n",
    "features.to_csv('./1_Features_raw/Regression_Speaker_Visual_hog_final_session2.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create CV dataset \n",
    "## (1) For Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test sessions =  [1, 2, 3]\n"
     ]
    }
   ],
   "source": [
    "# manually delete the first two cols\n",
    "features = pd.read_csv('./1_Features_raw/Classification_Speaker_Visual_Hog_6PNN_session2.csv')\n",
    "participate = pd.read_csv(\"Final_results_0620_1721.csv\")\n",
    "for cv_idx, key in enumerate(cv_dataset):\n",
    "    Test_sessions = cv_dataset[key][\"Test\"]\n",
    "    print(\"Test sessions = \",Test_sessions )\n",
    "    Validation_sessions = cv_dataset[key][\"Validation\"]\n",
    "    Train_sessions = cv_dataset[key][\"Train\"]\n",
    "    \n",
    "    # ---------------------\n",
    "    # load data\n",
    "    # ---------------------\n",
    "    Test_data = features[features['Session'].isin(Test_sessions)]\n",
    "    Test_data.to_csv(f\"./CV_Features/ClassificationFeatures/Test_CV_{cv_idx+1}.csv\")\n",
    "    Validation_data = features[features['Session'].isin(Validation_sessions)]\n",
    "    Train_data = features[features['Session'].isin(Train_sessions)]\n",
    "\n",
    "    # ---------------------\n",
    "    # speaker independent\n",
    "    # ---------------------\n",
    "    # (1) delete instance\n",
    "    delete_info = set()\n",
    "    Test_Overlap = participate[participate['Round'].isin(cv_dataset[key][\"Test\"])]\n",
    "    for idx, item in Test_Overlap.iterrows():\n",
    "        values = set(item.values[6:-1])\n",
    "        for temp in values:\n",
    "            if type(temp)!=float:\n",
    "                if int(temp.split('-')[0]) not in Test_sessions:\n",
    "                    if int(temp.split('-')[0])<10:\n",
    "                        temp = '0'+ temp\n",
    "                        delete_info.add(temp.replace(\"-\",\"_\"))\n",
    "                    else:\n",
    "                         delete_info.add(temp.replace(\"-\",\"_\"))\n",
    "    print(delete_info)\n",
    "    \n",
    "    # (2) 整理Validation and Train data\n",
    "    for idx, item in Validation_data.iterrows():\n",
    "        if item['VideoName'][:5] in list(delete_info):\n",
    "            Validation_data.drop(labels = idx,inplace=True)\n",
    "    Validation_data.to_csv(f\"./CV_Features/ClassificationFeatures/Validation_CV_{cv_idx+1}.csv\")\n",
    "    \n",
    "    for idx, item in Train_data.iterrows():\n",
    "        if item['VideoName'][:5] in list(delete_info):\n",
    "            Train_data.drop(labels = idx,inplace=True)\n",
    "    Train_data.to_csv(f\"./CV_Features/ClassificationFeatures/Train_CV_{cv_idx+1}.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (2) For Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test sessions =  [1, 2, 3]\n",
      "{'08_05', '12_05', '10_05', '09_09', '21_04', '18_02', '06_08', '08_04', '07_05', '07_03', '13_08', '05_04', '08_03', '22_09', '20_06', '05_08', '20_02', '16_04', '17_04', '20_05', '09_06', '21_02', '13_01', '12_02', '11_03', '14_09', '16_02', '18_01', '21_08', '21_07', '20_03', '09_01', '04_02', '04_04', '04_01', '15_02', '16_08', '17_06', '09_07'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/pandas/core/frame.py:4167: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return super().drop(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test sessions =  [4, 5, 6]\n",
      "{'12_04', '11_07', '18_04', '10_09', '10_05', '21_04', '28_01', '15_07', '07_05', '12_07', '03_09', '09_07', '11_09', '08_03', '08_08', '14_07', '12_01', '11_08', '16_09', '18_03', '03_03', '17_04', '01_01', '15_05', '24_04', '10_04', '02_09', '07_04', '20_01', '14_06', '10_02', '11_04', '21_01', '03_06', '11_01', '10_07', '13_09', '15_02', '16_08', '22_06', '11_02', '23_01', '09_03'}\n",
      "Test sessions =  [7, 8, 9]\n",
      "{'12_05', '21_09', '18_08', '18_06', '05_05', '01_02', '05_04', '11_08', '18_03', '14_02', '20_06', '02_08', '20_09', '22_05', '24_09', '16_04', '20_02', '01_01', '20_05', '12_08', '01_09', '12_03', '17_08', '10_04', '13_01', '11_06', '12_02', '12_09', '10_08', '10_03', '20_01', '04_05', '21_01', '13_06', '18_07', '03_06', '14_09', '16_02', '18_01', '04_04', '21_07', '03_01', '06_09', '03_05', '02_05', '11_05', '17_06', '13_07'}\n"
     ]
    }
   ],
   "source": [
    "# manually delete the first two cols\n",
    "features = pd.read_csv('./1_Features_raw/Regression_Speaker_Visual_hog_final_session2.csv')\n",
    "participate = pd.read_csv(\"Final_results_0620_1721.csv\")\n",
    "for cv_idx, key in enumerate(cv_dataset):\n",
    "    Test_sessions = cv_dataset[key][\"Test\"]\n",
    "    print(\"Test sessions = \",Test_sessions )\n",
    "    Validation_sessions = cv_dataset[key][\"Validation\"]\n",
    "    Train_sessions = cv_dataset[key][\"Train\"]\n",
    "    \n",
    "    # ---------------------\n",
    "    # load data\n",
    "    # ---------------------\n",
    "    Test_data = features[features['Session'].isin(Test_sessions)]\n",
    "    Test_data.to_csv(f\"./CV_Features/RegressionFeatures/Test_CV_{cv_idx+1}.csv\")\n",
    "    Validation_data = features[features['Session'].isin(Validation_sessions)]\n",
    "    Train_data = features[features['Session'].isin(Train_sessions)]\n",
    "\n",
    "    # ---------------------\n",
    "    # speaker independent\n",
    "    # ---------------------\n",
    "    # (1) delete instance\n",
    "    delete_info = set()\n",
    "    Test_Overlap = participate[participate['Round'].isin(cv_dataset[key][\"Test\"])]\n",
    "    for idx, item in Test_Overlap.iterrows():\n",
    "        values = set(item.values[6:-1])\n",
    "        for temp in values:\n",
    "            if type(temp)!=float:\n",
    "                if int(temp.split('-')[0]) not in Test_sessions:\n",
    "                    if int(temp.split('-')[0])<10:\n",
    "                        temp = '0'+ temp\n",
    "                        delete_info.add(temp.replace(\"-\",\"_\"))\n",
    "                    else:\n",
    "                         delete_info.add(temp.replace(\"-\",\"_\"))\n",
    "    print(delete_info)\n",
    "    \n",
    "    # (2) 整理Validation and Train data\n",
    "    for idx, item in Validation_data.iterrows():\n",
    "        if item['VideoName'][:5] in list(delete_info):\n",
    "            Validation_data.drop(labels = idx,inplace=True)\n",
    "    Validation_data.to_csv(f\"./CV_Features/RegressionFeatures/Validation_CV_{cv_idx+1}.csv\")\n",
    "    \n",
    "    for idx, item in Train_data.iterrows():\n",
    "        if item['VideoName'][:5] in list(delete_info):\n",
    "            Train_data.drop(labels = idx,inplace=True)\n",
    "    Train_data.to_csv(f\"./CV_Features/RegressionFeatures/Train_CV_{cv_idx+1}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.1 64-bit",
   "language": "python",
   "name": "python37164bit395e14d61e31467c92df2f870180e68d"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
